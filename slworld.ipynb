{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "850a6422-9417-4146-a7d5-098fe5addcc7",
      "metadata": {
        "id": "850a6422-9417-4146-a7d5-098fe5addcc7"
      },
      "outputs": [],
      "source": [
        "# !pip install import_ipynb --quiet\n",
        "# !git clone https://github.com/gmshroff/aiagentarch.git\n",
        "# %cd aiagentarch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0e8289f-e2f8-43d4-bfd4-b0913edf0f29",
      "metadata": {
        "id": "d0e8289f-e2f8-43d4-bfd4-b0913edf0f29"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc4c0c4f-ad65-4e65-a307-dd2db1c32ff4",
      "metadata": {
        "id": "dc4c0c4f-ad65-4e65-a307-dd2db1c32ff4"
      },
      "outputs": [],
      "source": [
        "import import_ipynb\n",
        "import utils\n",
        "import models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67e0c3d3-6686-4413-b5be-f9bd31ad73ab",
      "metadata": {
        "id": "67e0c3d3-6686-4413-b5be-f9bd31ad73ab"
      },
      "source": [
        "### World and Agents for Supervised Learning Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6517152-bd6d-4d36-a5b6-a8b95f2d100c",
      "metadata": {
        "id": "a6517152-bd6d-4d36-a5b6-a8b95f2d100c"
      },
      "outputs": [],
      "source": [
        "from aiagentbase import AIAgent,Controller,Memory,Perception,Actor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20e9f4fa-0689-4463-9fdf-48908932a18b",
      "metadata": {
        "id": "20e9f4fa-0689-4463-9fdf-48908932a18b"
      },
      "outputs": [],
      "source": [
        "class SLWorld():\n",
        "    def __init__(self,train_ds,test_ds,n_classes):\n",
        "        self.train_ds=train_ds\n",
        "        self.test_ds=test_ds\n",
        "        self.action_space=spaces.Discrete(n_classes)\n",
        "        self.obs_dim=self.train_ds[0][0].shape[-1]\n",
        "        high = np.inf*np.ones(self.obs_dim)\n",
        "        low = -high\n",
        "        self.observation_space=spaces.Box(high=high,low=low)\n",
        "    def run(self,agent=None,n_episodes=10):\n",
        "        self.test_rew=0\n",
        "        self.test_rewL=[]\n",
        "        if 'training' not in agent.__dict__: agent.training=True\n",
        "        for episode in range(n_episodes):\n",
        "            tot_rew=0\n",
        "            agent.begin()\n",
        "            count=0\n",
        "            for sample,label in self.train_ds:\n",
        "                count+=1\n",
        "                done=(count==len(train_ds))\n",
        "                action=agent.act(sample)\n",
        "                reward=(self.accuracy(action,label),{'label':label})\n",
        "                agent.reward((reward[0],done,reward[1]))\n",
        "                tot_rew+=reward[0]\n",
        "            if 'end' in dir(agent): agent.end()\n",
        "            print('episode: ',episode,'avg reward: ',tot_rew/len(train_ds))\n",
        "        agent.set_training(False)\n",
        "        print('Training Over')\n",
        "        agent.begin()\n",
        "        for sample,label in self.test_ds:\n",
        "            action=agent.act(sample)\n",
        "            reward=(self.accuracy(action,label),{})\n",
        "            agent.reward(reward)\n",
        "            self.test_rewL+=[reward]\n",
        "            self.test_rew+=reward[0]\n",
        "        print('Test Over; Accuracy: ',self.test_rew/len(self.test_ds))\n",
        "        return self.test_rew/len(self.test_ds)\n",
        "    def accuracy(self,action,label):\n",
        "        if (type(action)==np.ndarray): action=action[-1]\n",
        "        if action==label[-1]: return 1\n",
        "        else: return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a95733e-f863-432b-ac20-753d221e6fa9",
      "metadata": {
        "id": "9a95733e-f863-432b-ac20-753d221e6fa9"
      },
      "outputs": [],
      "source": [
        "class MLPAgent(AIAgent):\n",
        "    def __init__(self,action_space,net):\n",
        "        super().__init__()\n",
        "        ##Augmenting AIAgent\n",
        "        self.actor=self.Actor(parent=self,model=net)\n",
        "        self.action_space=action_space\n",
        "        self.tot_rew=0\n",
        "        self.rewL=[]\n",
        "        \n",
        "    class Actor(Actor):\n",
        "        def __init__(self,parent,model):\n",
        "            super().__init__(parent=parent,model=model)\n",
        "        def call_model(self,state):\n",
        "            ##Overriding AIAgent\n",
        "            lpreds=self.model(state)\n",
        "            action=torch.argmax(lpreds,axis=1)\n",
        "            return action\n",
        "        def compute_reward(self,reward):\n",
        "            return reward[0]\n",
        "\n",
        "    def set_training(self,value):\n",
        "        self.training=value\n",
        "    def avg_rew(self):\n",
        "        return sum(self.rewL)/len(self.rewL)\n",
        "    def reward(self,rew):\n",
        "        ##Augmenting AIAgent\n",
        "        if self.training:\n",
        "            prev_state=self.memory.sar_memory[self.time-1]['state']\n",
        "            net=self.actor.model\n",
        "            action=torch.argmax(net(prev_state))\n",
        "            prev_action=self.memory.sar_memory[self.time-1]['action']\n",
        "            net,_,_=models.Train(net,[(prev_state,rew[2]['label'])],epochs=1)\n",
        "        self.tot_rew+=rew[0]\n",
        "        return super().reward(rew)\n",
        "    def begin(self):\n",
        "        ##Augmenting AIAgent\n",
        "        self.rewL+=[self.tot_rew]\n",
        "        super().begin()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28bf41c1-febf-4a54-9fe1-d57de4856cd8",
      "metadata": {
        "id": "28bf41c1-febf-4a54-9fe1-d57de4856cd8"
      },
      "outputs": [],
      "source": [
        "class MLPBatchAgent(MLPAgent):\n",
        "    def __init__(self,action_space,net,epochs=1):\n",
        "        super().__init__(action_space,net)\n",
        "        self.epochs=epochs\n",
        "    def reward(self,rew):\n",
        "        self.tot_rew+=rew[0]\n",
        "        # Bypass parent class' reward\n",
        "        return super(MLPAgent,self).reward(rew) \n",
        "    def end(self):\n",
        "        if not self.training: return\n",
        "        #Gather data from sar memory\n",
        "        print('Agent Training')\n",
        "        M=self.memory.sar_memory\n",
        "        P=self.memory.perceptual_memory\n",
        "        y=[P[t]['reward'][2]['label'] \n",
        "           for t in P if t>=0 and 'label' in P[t]['reward'][2]]\n",
        "        X=[M[t]['state'] for t in M if t>=0][0:len(y)]\n",
        "        #Train \n",
        "        self.net,_,_=models.Train(net,[(x,l) for x,l in zip(X,y)],epochs=self.epochs,verbose=True)\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd48ae6d-73d0-40db-b4ef-2bf1de69d94a",
      "metadata": {
        "id": "bd48ae6d-73d0-40db-b4ef-2bf1de69d94a"
      },
      "outputs": [],
      "source": [
        "train_ds, test_ds, dloader = utils.euclideanDataset(n_samples=10000,n_features=20,n_classes=10,batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beba7a9b-b0d8-4b2d-985c-fa292e13fb0b",
      "metadata": {
        "id": "beba7a9b-b0d8-4b2d-985c-fa292e13fb0b"
      },
      "outputs": [],
      "source": [
        "train_ds=[(s.unsqueeze(0),l.unsqueeze(0)) for s,l in train_ds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6227e2aa-d30f-4136-a3ac-042c2684a34d",
      "metadata": {
        "id": "6227e2aa-d30f-4136-a3ac-042c2684a34d"
      },
      "outputs": [],
      "source": [
        "test_ds=[(s.unsqueeze(0),l.unsqueeze(0)) for s,l in test_ds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eafa0f4-1fe2-4d6f-960f-7a0b5c2d4e3a",
      "metadata": {
        "id": "1eafa0f4-1fe2-4d6f-960f-7a0b5c2d4e3a"
      },
      "outputs": [],
      "source": [
        "net=models.MLP(dims=[20,32,10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01ed6686-899a-4f14-9114-fc6f42271701",
      "metadata": {
        "id": "01ed6686-899a-4f14-9114-fc6f42271701"
      },
      "outputs": [],
      "source": [
        "# net,_,_=models.Train(net,train_ds,epochs=5,verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08e88101-ba10-43b7-a1b2-85496eae3c5e",
      "metadata": {
        "id": "08e88101-ba10-43b7-a1b2-85496eae3c5e"
      },
      "outputs": [],
      "source": [
        "slworld=SLWorld(train_ds,test_ds,n_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "163fa5ee-4969-4861-9c22-648e46005c50",
      "metadata": {
        "id": "163fa5ee-4969-4861-9c22-648e46005c50"
      },
      "outputs": [],
      "source": [
        "agent=MLPAgent(slworld.action_space,net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aacd7e8a-09ca-4c20-b9a0-ef3b788993a7",
      "metadata": {
        "id": "aacd7e8a-09ca-4c20-b9a0-ef3b788993a7"
      },
      "outputs": [],
      "source": [
        "agent=MLPBatchAgent(slworld.action_space,net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a80584f7-7b2a-4d30-9c7d-a44213db71ee",
      "metadata": {
        "tags": [],
        "id": "a80584f7-7b2a-4d30-9c7d-a44213db71ee"
      },
      "outputs": [],
      "source": [
        "slworld.run(agent=agent,n_episodes=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a93b3dd-d9d5-4fa3-8119-9d5f6b5af75c",
      "metadata": {
        "id": "3a93b3dd-d9d5-4fa3-8119-9d5f6b5af75c"
      },
      "outputs": [],
      "source": [
        "M=agent.memory.perceptual_memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35550e50-1e37-49d5-a6a8-db1c268397c8",
      "metadata": {
        "tags": [],
        "id": "35550e50-1e37-49d5-a6a8-db1c268397c8"
      },
      "outputs": [],
      "source": [
        "[(t,M[t]) for t in M if M[t]['reward'][1]==True]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a573df0-6a9a-4ed5-bf6f-a131f9e604eb",
      "metadata": {
        "id": "7a573df0-6a9a-4ed5-bf6f-a131f9e604eb"
      },
      "outputs": [],
      "source": [
        "S=agent.memory.sar_memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "383d0694-9f77-49f1-a0bf-a09a71ca0622",
      "metadata": {
        "id": "383d0694-9f77-49f1-a0bf-a09a71ca0622"
      },
      "outputs": [],
      "source": [
        "S[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38af7697-8fcd-4846-81c7-465ba2ee72e3",
      "metadata": {
        "id": "38af7697-8fcd-4846-81c7-465ba2ee72e3"
      },
      "outputs": [],
      "source": [
        "agent.set_training(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48f94740-2db8-4030-a4ca-3005c8cc5a00",
      "metadata": {
        "id": "48f94740-2db8-4030-a4ca-3005c8cc5a00"
      },
      "source": [
        "### Supervised-Learning Enviroment trained using off-the shelf RL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdde0b00-ce6c-46cf-a270-61ad64fe2df6",
      "metadata": {
        "id": "cdde0b00-ce6c-46cf-a270-61ad64fe2df6"
      },
      "outputs": [],
      "source": [
        "class SLEnv(gym.Env):\n",
        "    def __init__(self,ds,n_classes,batch_size=1):\n",
        "        self.ds=ds\n",
        "        self.n=len(ds)\n",
        "        self.obs_dim=self.ds[0][0].shape[-1]\n",
        "        self.action_space=spaces.Discrete(n_classes)\n",
        "        high = np.inf*np.ones(self.obs_dim)\n",
        "        low = -high\n",
        "        self.observation_space=spaces.Box(high=high,low=low)\n",
        "        self.counter=0\n",
        "        self.verbose=False\n",
        "        self.ep_reward=0\n",
        "        self.epoch=0\n",
        "        self.batch_size=batch_size\n",
        "    def set_verbose(self,value):\n",
        "        self.verbose=value\n",
        "    def reset(self):\n",
        "        # self.counter=0\n",
        "        return self.ds[self.counter][0]\n",
        "    def step(self,action):\n",
        "        state=self.ds[self.counter][0]\n",
        "        label=self.ds[self.counter][1]\n",
        "        # print(action,label)\n",
        "        reward=self.accuracy(action,label)\n",
        "        self.ep_reward+=reward\n",
        "        # print(reward)\n",
        "        if self.counter==self.n-1:\n",
        "            self.counter=0\n",
        "            if self.verbose: print(f\"epoch {self.epoch} avg_reward {self.ep_reward/self.n}\")\n",
        "            self.ep_reward=0\n",
        "            self.epoch+=1\n",
        "        else: self.counter+=1\n",
        "        if self.counter%self.batch_size==0:done=True\n",
        "        else:done=False\n",
        "        state=self.ds[self.counter][0]\n",
        "        return state,reward,done,{}\n",
        "    def accuracy(self,action,label):\n",
        "        if (type(action)==np.ndarray): action=action[-1]\n",
        "        if action==label[-1]: return 1\n",
        "        else: return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c884cf46-8adb-4ec4-81f8-9b60cf8cf642",
      "metadata": {
        "id": "c884cf46-8adb-4ec4-81f8-9b60cf8cf642"
      },
      "outputs": [],
      "source": [
        "slenv=SLEnv(train_ds,10,batch_size=1)\n",
        "slenv.set_verbose(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26127c09-1fcf-40d8-90dc-e21df9394c5f",
      "metadata": {
        "tags": [],
        "id": "26127c09-1fcf-40d8-90dc-e21df9394c5f"
      },
      "outputs": [],
      "source": [
        "for ep in range(int(slenv.n/slenv.batch_size)):\n",
        "    done=False\n",
        "    while not done:\n",
        "        state,reward,done,_=slenv.step(slenv.action_space.sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f5afbd2-2000-4bd1-b984-34f4c9a8e4cf",
      "metadata": {
        "id": "4f5afbd2-2000-4bd1-b984-34f4c9a8e4cf"
      },
      "outputs": [],
      "source": [
        "model=A2C('MlpPolicy', slenv, verbose=0, gamma=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4df80757-9d03-4dfc-a638-7f1af02c3d8f",
      "metadata": {
        "id": "4df80757-9d03-4dfc-a638-7f1af02c3d8f"
      },
      "outputs": [],
      "source": [
        "model=PPO('MlpPolicy', slenv, verbose=0, gamma=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdb2e8bd-4f6b-4e7d-bada-cf99c055edfe",
      "metadata": {
        "id": "fdb2e8bd-4f6b-4e7d-bada-cf99c055edfe"
      },
      "outputs": [],
      "source": [
        "model=DQN('MlpPolicy', slenv, verbose=0, gamma=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "899a135e-9911-4dd7-a8b9-896549e5ae18",
      "metadata": {
        "tags": [],
        "id": "899a135e-9911-4dd7-a8b9-896549e5ae18"
      },
      "outputs": [],
      "source": [
        "model.learn(total_timesteps=50000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11d857d5-dc80-4a22-a3d6-e5d222711aff",
      "metadata": {
        "id": "11d857d5-dc80-4a22-a3d6-e5d222711aff"
      },
      "outputs": [],
      "source": [
        "tsenv=SLEnv(test_ds,10,batch_size=len(train_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6687c5ce-f3af-4df5-af41-0fc424db2eae",
      "metadata": {
        "tags": [],
        "id": "6687c5ce-f3af-4df5-af41-0fc424db2eae"
      },
      "outputs": [],
      "source": [
        "env=tsenv\n",
        "# env=slenv\n",
        "state=env.reset()\n",
        "tot_rew=0\n",
        "rewL=[]\n",
        "count=0\n",
        "for ep in range(1):\n",
        "    done=False\n",
        "    while not done:\n",
        "        action,_=model.predict(state)\n",
        "        # print(action,slenv.ds[slenv.counter][1])\n",
        "        state,reward,done,_=env.step(action)\n",
        "        # print(reward)\n",
        "        tot_rew+=reward\n",
        "        count+=1\n",
        "        rewL+=[reward]\n",
        "print(tot_rew/count)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41e24475-66fc-4544-a0fe-20297b9246ac",
      "metadata": {
        "id": "41e24475-66fc-4544-a0fe-20297b9246ac"
      },
      "source": [
        "### Training an AI Agent's Model using Generic AI Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afefe229-241d-42fb-b5a2-0fe4b4f36c28",
      "metadata": {
        "id": "afefe229-241d-42fb-b5a2-0fe4b4f36c28"
      },
      "outputs": [],
      "source": [
        "from queue import Queue\n",
        "from threading import Thread\n",
        "import threading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6f936a8-18d3-4050-8dd3-55cd58dfd441",
      "metadata": {
        "id": "f6f936a8-18d3-4050-8dd3-55cd58dfd441"
      },
      "outputs": [],
      "source": [
        "from aiagentbase import RLAgent\n",
        "from stable_baselines3 import PPO,DQN,A2C,SAC\n",
        "from threading import Thread\n",
        "import threading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f938dfc-36bd-4e18-87c0-584c3c8c0f80",
      "metadata": {
        "id": "7f938dfc-36bd-4e18-87c0-584c3c8c0f80"
      },
      "outputs": [],
      "source": [
        "agent=RLAgent(A2C,slworld.action_space,slworld.observation_space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44edef18-00b7-4098-96f8-01f51bccc195",
      "metadata": {
        "id": "44edef18-00b7-4098-96f8-01f51bccc195"
      },
      "outputs": [],
      "source": [
        "agent.debug=False\n",
        "agent.use_memory=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1cce67f-0995-42fa-b1a1-1753133a37f6",
      "metadata": {
        "id": "d1cce67f-0995-42fa-b1a1-1753133a37f6"
      },
      "outputs": [],
      "source": [
        "agent.rewL=[]\n",
        "agent.tot_rew=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb1e7d8e-eae8-43f4-98b2-28f652813c17",
      "metadata": {
        "id": "bb1e7d8e-eae8-43f4-98b2-28f652813c17"
      },
      "outputs": [],
      "source": [
        "world=slworld"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73048827-76b1-46e0-bb9b-32613b25fea8",
      "metadata": {
        "id": "73048827-76b1-46e0-bb9b-32613b25fea8"
      },
      "outputs": [],
      "source": [
        "worldthread=Thread(name='world',target=world.run,args=(agent,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85eeef3f-d4cd-4048-a4d1-193e7c0207c9",
      "metadata": {
        "id": "85eeef3f-d4cd-4048-a4d1-193e7c0207c9"
      },
      "outputs": [],
      "source": [
        "agent.start(training_steps=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "272031fa-5cc0-4e8c-8dd5-5c4b7c568598",
      "metadata": {
        "id": "272031fa-5cc0-4e8c-8dd5-5c4b7c568598"
      },
      "outputs": [],
      "source": [
        "worldthread.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de878c07-e022-4e18-96dc-52c98494bf64",
      "metadata": {
        "tags": [],
        "id": "de878c07-e022-4e18-96dc-52c98494bf64"
      },
      "outputs": [],
      "source": [
        "# world.run(agent=agent,n_episodes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70ab278f-4755-4121-a5c6-0b86f98a3d66",
      "metadata": {
        "id": "70ab278f-4755-4121-a5c6-0b86f98a3d66"
      },
      "outputs": [],
      "source": [
        "agent.logL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04b4a528-95bd-46df-89b5-24208287a20f",
      "metadata": {
        "id": "04b4a528-95bd-46df-89b5-24208287a20f"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b24174f7-ddec-495e-bd52-9612889571c2",
      "metadata": {
        "id": "b24174f7-ddec-495e-bd52-9612889571c2"
      },
      "outputs": [],
      "source": [
        "np.gradient(agent.rewL).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "592b52fb-577e-4ebd-9b8d-d63b3c1680fb",
      "metadata": {
        "id": "592b52fb-577e-4ebd-9b8d-d63b3c1680fb"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.gradient(agent.rewL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7b97138-511d-4bac-acac-b20f19e2c0e9",
      "metadata": {
        "id": "b7b97138-511d-4bac-acac-b20f19e2c0e9"
      },
      "outputs": [],
      "source": [
        "for thread in threading.enumerate(): \n",
        "    print(thread.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec6a2896-cc55-46aa-9103-ae19f9bffc32",
      "metadata": {
        "id": "ec6a2896-cc55-46aa-9103-ae19f9bffc32"
      },
      "outputs": [],
      "source": [
        "agent.memory.perceptual_memory[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf4e9204-9c3a-4c27-96a8-9bbd839776c5",
      "metadata": {
        "id": "bf4e9204-9c3a-4c27-96a8-9bbd839776c5"
      },
      "outputs": [],
      "source": [
        "agent.memory.sar_memory[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cfd806e-69a2-486e-b216-1f4c93ba26ae",
      "metadata": {
        "id": "4cfd806e-69a2-486e-b216-1f4c93ba26ae"
      },
      "outputs": [],
      "source": [
        "train_ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c90b9d-231c-4baf-91f2-a5f789e09c61",
      "metadata": {
        "id": "c0c90b9d-231c-4baf-91f2-a5f789e09c61"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}